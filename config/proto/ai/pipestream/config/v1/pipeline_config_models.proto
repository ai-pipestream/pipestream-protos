syntax = "proto3";

package ai.pipestream.config.v1;

import "ai/pipestream/data/v1/pipeline_core_types.proto";
import "google/protobuf/duration.proto";
import "google/protobuf/struct.proto";
import "google/protobuf/timestamp.proto";

option java_multiple_files = true;
option java_package = "ai.pipestream.config.v1";

// V1 Graph-first pipeline configuration models

// Cluster configuration and metadata container.
//
// Represents a logical grouping of pipeline nodes with access control for Kafka topics and gRPC services.
// Clusters provide namespace isolation and enable cross-cluster routing.
message Cluster {
  // Unique identifier for this cluster.
  string cluster_id = 1;
  // Human-readable cluster name.
  string name = 2;
  // Additional cluster metadata and configuration.
  ClusterMetadata metadata = 3;
  // Kafka topics this cluster is allowed to access.
  repeated string allowed_kafka_topics = 4;
  // gRPC services this cluster is allowed to invoke.
  repeated string allowed_grpc_services = 5;
}

// Cluster metadata and creation information.
message ClusterMetadata {
  // Display name for the cluster.
  string name = 1;
  // Timestamp when the cluster was created.
  google.protobuf.Timestamp created_at = 2;
  // Flexible key-value metadata storage.
  google.protobuf.Struct metadata = 3;
}

// Pipeline graph defining node topology and data flow.
//
// Represents a complete pipeline as a directed acyclic graph (DAG) of processing nodes.
// Nodes are embedded within the graph to create self-contained snapshots for versioning.
// Each graph version is a complete, immutable state that includes all node definitions.
message PipelineGraph {
  // Unique identifier for this graph.
  string graph_id = 1;
  // Cluster this graph belongs to.
  string cluster_id = 2;
  // Human-readable graph name.
  string name = 3;
  // Optional description of the graph's purpose.
  string description = 4;
  // Full GraphNode definitions that comprise this graph.
  //
  // Nodes are embedded rather than referenced to ensure graph versions are
  // self-contained snapshots. This simplifies versioning, rollback, and
  // distribution via Kafka (single message contains complete graph state).
  repeated GraphNode nodes = 5;
  // Edges defining connections between nodes.
  repeated GraphEdge edges = 6;
  // Operating mode (design or production).
  GraphMode mode = 7;
  // Timestamp when the graph was created.
  google.protobuf.Timestamp created_at = 8;
  // Timestamp of last modification.
  google.protobuf.Timestamp modified_at = 9;
  // Version number for optimistic locking.
  //
  // Incremented on each update to detect concurrent modifications.
  // Clients should read the current version before updates and include it
  // in update requests. Updates fail if the version doesn't match.
  int64 version = 10;
}

// Graph node representing an individual processing step.
//
// Nodes exist independently and can be referenced DNS-style by globally unique IDs.
// Supports both production deployment and frontend design/simulation modes.
message GraphNode {
  // Globally unique identifier in format cluster_id.node_name (e.g., "prod.chunker-v1").
  string node_id = 1;
  // Cluster this node belongs to.
  string cluster_id = 2;
  // Human-readable node name.
  string name = 3;
  // Type of node (connector, processor, or sink).
  NodeType node_type = 4;
  // Reference to the ModuleDefinition that implements this node.
  string module_id = 5;
  // Custom configuration for this node instance.
  ai.pipestream.data.v1.ProcessConfiguration custom_config = 6;
  // Visibility scope across clusters.
  ClusterVisibility visibility = 7;
  // Operating mode (design or production).
  NodeMode mode = 9;

  // Kafka input topic (production mode only). Typically matches node_id (e.g., "prod.chunker-v1").
  string kafka_input_topic = 10;
  // Auto-generated repository path (production mode only) in format /clusters/{cluster_id}/nodes/{node_id}.
  string repository_path = 11;

  // Design mode configuration for frontend simulation.
  DesignModeConfig design_config = 12;

  // Timestamp when the node was created.
  google.protobuf.Timestamp created_at = 13;
  // Timestamp of last modification.
  google.protobuf.Timestamp modified_at = 14;
  // Dead Letter Queue configuration for failed message handling.
  //
  // When enabled, messages that fail processing are routed to a DLQ topic
  // for later inspection and reprocessing.
  DlqConfig dlq_config = 15;

  // Field mappings applied before module processing.
  //
  // These mappings transform the document before it is sent to the module.
  // Use cases include field renaming, data extraction, and format conversion.
  repeated ai.pipestream.data.v1.ProcessingMapping pre_mappings = 16;
  // Field mappings applied after module processing.
  //
  // These mappings transform the document after the module returns.
  // Use cases include output normalization and field consolidation.
  repeated ai.pipestream.data.v1.ProcessingMapping post_mappings = 17;
  // CEL expressions to filter documents before processing.
  //
  // All conditions must evaluate to true for the document to be processed.
  // If any condition evaluates to false, the document skips this node
  // and proceeds to the next node in the pipeline without processing.
  // Available context variables:
  //   - document: The PipeDoc being processed
  //   - stream: The PipeStream object (metadata, history, etc.)
  // Example expressions:
  //   - "document.search_metadata.language == 'en'"
  //   - "stream.metadata.context_params['skip_ocr'] != 'true'"
  //   - "document.search_metadata.content_length > 100"
  repeated string filter_conditions = 18;
  // Whether to save the document to the repository even if processing fails.
  //
  // When true, the document is persisted to the repository even if the module
  // processing encounters an error. Useful for debugging and reprocessing.
  bool save_on_error = 19;
}

// Dead Letter Queue configuration for handling failed messages.
//
// Configures how failed messages are handled at a node, including retry behavior
// and topic routing for messages that exhaust all retry attempts.
message DlqConfig {
  // Whether DLQ handling is enabled for this node.
  //
  // When false, failed messages are logged but not routed to a DLQ.
  bool enabled = 1;
  // Custom DLQ topic name override.
  //
  // If not set, defaults to "{node_id}.dlq" naming convention.
  string topic_override = 2;
  // Maximum number of retry attempts before sending to DLQ.
  //
  // A value of 0 means no retries (immediate DLQ on failure).
  int32 max_retries = 3;
  // Initial backoff duration between retry attempts.
  //
  // Subsequent retries use exponential backoff based on this value.
  google.protobuf.Duration initial_backoff = 4;
  // Maximum backoff duration cap.
  //
  // Exponential backoff will not exceed this duration.
  google.protobuf.Duration max_backoff = 5;
  // Backoff multiplier for exponential backoff.
  //
  // Each retry waits (initial_backoff * multiplier^attempt) up to max_backoff.
  // Default is 2.0 if not specified.
  double backoff_multiplier = 6;
  // Whether to include the original message payload in DLQ records.
  //
  // When true, the full PipeStream is preserved for debugging.
  // When false, only metadata and error info are stored.
  bool include_payload = 7;
}

// Graph edge defining a connection between two nodes.
//
// Edges can span clusters to enable cross-cluster routing.
// Supports conditional routing and priority-based selection when multiple edges exist from a single node.
message GraphEdge {
  // Unique identifier for this edge.
  string edge_id = 1;
  // Source node ID.
  string from_node_id = 2;
  // Destination node ID.
  string to_node_id = 3;
  // Target cluster ID (optional, for cross-cluster edges).
  string to_cluster_id = 4;
  // CEL (Common Expression Language) condition for routing decisions.
  //
  // Evaluated at runtime to determine if this edge should be taken.
  // Uses org.projectnessie.cel:cel-tools for Java/Quarkus implementation.
  // Available context variables:
  //   - document: The PipeDoc being processed
  //   - metadata: StreamMetadata with processing history
  //   - context_params: Map of context parameters
  // Example expressions:
  //   - "document.search_metadata.language == 'en'"
  //   - "metadata.context_params['priority'] == 'high'"
  //   - "document.search_metadata.content_length > 1000"
  string condition = 5;
  // Priority for edge selection when multiple edges exist from the same node.
  //
  // Lower values indicate higher priority. When multiple edges have conditions
  // that evaluate to true, the edge with the lowest priority value is selected.
  int32 priority = 6;
  // Flag indicating whether this edge crosses cluster boundaries.
  bool is_cross_cluster = 7;
  // Transport mechanism for this edge.
  //
  // Specifies how data flows across this edge. Defaults to TRANSPORT_TYPE_MESSAGING.
  TransportType transport_type = 8;
  // Kafka topic override for this edge.
  //
  // When set, messages are routed through this topic instead of the default
  // node-based topic naming. Useful for custom routing patterns.
  string kafka_topic = 9;
  // Maximum number of hops allowed through this edge.
  //
  // Prevents infinite loops in cyclic graph configurations.
  // A value of 0 means unlimited (use with caution).
  int32 max_hops = 10;
}

// Module definition containing metadata and configuration schema.
//
// Defines a reusable processing module that can be instantiated as graph nodes.
// Includes schema references and default configuration.
message ModuleDefinition {
  // Unique identifier for this module.
  string module_id = 1;
  // Implementation class or service name.
  string implementation_name = 2;
  // gRPC service name for this module.
  string grpc_service_name = 3;
  // Reference to the configuration schema for this module.
  SchemaReference config_schema = 4;
  // Default configuration values.
  google.protobuf.Struct default_config = 5;
  // Visibility scope for this module.
  ModuleVisibility visibility = 6;
  // Timestamp when the module was created.
  google.protobuf.Timestamp created_at = 7;
  // Timestamp of last modification.
  google.protobuf.Timestamp modified_at = 8;
}

// JsonConfigOptions is deprecated - use ai.pipestream.data.v1.ProcessConfiguration instead.
// Keeping this comment for migration reference.

// Real-time notification of graph topology changes.
//
// Streamed to subscribers when nodes, edges, graphs, or modules are created, updated, or deleted.
message GraphUpdateNotification {
  // Cluster where the update occurred.
  string cluster_id = 1;
  // Type of update operation.
  UpdateType update_type = 2;
  // The updated entity (node, edge, graph, or module).
  oneof target {
    // Updated graph node.
    GraphNode node = 3;
    // Updated graph edge.
    GraphEdge edge = 4;
    // Updated pipeline graph.
    PipelineGraph graph = 5;
    // Updated module definition.
    ModuleDefinition module = 6;
  }
  // Timestamp when the update occurred.
  google.protobuf.Timestamp timestamp = 7;
}

// Type of configuration update operation.
enum UpdateType {
  // Unspecified update type.
  UPDATE_TYPE_UNSPECIFIED = 0;
  // Entity was created.
  UPDATE_TYPE_CREATED = 1;
  // Entity was updated.
  UPDATE_TYPE_UPDATED = 2;
  // Entity was deleted.
  UPDATE_TYPE_DELETED = 3;
}

// Reference to a versioned schema in a schema registry.
message SchemaReference {
  // Schema subject name.
  string subject = 1;
  // Schema version number.
  int32 version = 2;
}

// Type of graph node in the pipeline.
enum NodeType {
  // Unspecified node type.
  NODE_TYPE_UNSPECIFIED = 0;
  // Entry point node that receives data from external sources.
  NODE_TYPE_CONNECTOR = 1;
  // Processing node that transforms data.
  NODE_TYPE_PROCESSOR = 2;
  // Exit point node that outputs data to external systems.
  NODE_TYPE_SINK = 3;
}

// Transport mechanism for node communication.
enum TransportType {
  // Unspecified transport type.
  TRANSPORT_TYPE_UNSPECIFIED = 0;
  // Messaging-based transport using topics and subscriptions.
  TRANSPORT_TYPE_MESSAGING = 1;
  // gRPC-based transport for synchronous communication.
  TRANSPORT_TYPE_GRPC = 2;
}

// Visibility scope for nodes across clusters.
enum ClusterVisibility {
  // Unspecified visibility.
  CLUSTER_VISIBILITY_UNSPECIFIED = 0;
  // Visible only within this cluster.
  CLUSTER_VISIBILITY_PRIVATE = 1;
  // Visible to all subscribed clusters.
  CLUSTER_VISIBILITY_PUBLIC = 2;
  // Visible only to specific clusters.
  CLUSTER_VISIBILITY_RESTRICTED = 3;
}

// Operating mode for pipeline graphs.
enum GraphMode {
  // Unspecified mode.
  GRAPH_MODE_UNSPECIFIED = 0;
  // Design/simulation mode for frontend testing.
  GRAPH_MODE_DESIGN = 1;
  // Production mode for deployed and running pipelines.
  GRAPH_MODE_PRODUCTION = 2;
}

// Operating mode for individual nodes.
enum NodeMode {
  // Unspecified mode.
  NODE_MODE_UNSPECIFIED = 0;
  // Design-time node not yet deployed.
  NODE_MODE_DESIGN = 1;
  // Production node that is deployed and running.
  NODE_MODE_PRODUCTION = 2;
}

// Design mode configuration for frontend simulation and testing.
//
// Provides UI positioning, simulation behavior, sample data, and visual metadata
// for nodes in design mode before production deployment.
message DesignModeConfig {
  // X coordinate for node positioning on the canvas.
  int32 canvas_x = 1;
  // Y coordinate for node positioning on the canvas.
  int32 canvas_y = 2;

  // Whether to simulate processing in the frontend.
  bool simulate_processing = 3;
  // Simulated processing duration for UI feedback.
  google.protobuf.Duration simulated_processing_time = 4;
  // Simulated success rate (0.0-1.0) for error simulation and testing.
  double simulated_success_rate = 5;

  // Sample input data as JSON strings for testing.
  repeated string sample_input_data = 6;
  // Expected output data for validation.
  repeated string expected_output_data = 7;

  // Hex color code for node visualization (e.g., "#FF5733").
  string ui_color = 8;
  // Icon name or path for node representation.
  string ui_icon = 9;
  // Whether the node is collapsed in the UI.
  bool ui_collapsed = 10;
}

// Running instance of a pipeline with runtime configuration.
//
// Represents a deployed pipeline instance with status tracking, configuration overrides,
// and lifecycle timestamps.
message PipelineInstance {
  // Unique identifier for this pipeline instance.
  string instance_id = 1;
  // Reference to the pipeline definition this instance is based on.
  string pipeline_definition_id = 2;
  // Name of the cluster where this instance is running.
  string cluster_name = 3;
  // Human-readable instance name.
  string name = 4;
  // Optional description of this instance.
  string description = 5;
  // Current runtime status.
  PipelineInstanceStatus status = 6;
  // Per-step configuration overrides keyed by step ID.
  map<string, StepConfigOverride> config_overrides = 7;
  // Kafka topic prefix for this instance's messaging.
  string kafka_topic_prefix = 8;
  // Processing priority for this instance.
  int32 priority = 9;
  // Maximum parallelism allowed for this instance.
  int32 max_parallelism = 10;
  // Additional instance metadata.
  map<string, string> metadata = 11;
  // Timestamp when the instance was created.
  google.protobuf.Timestamp created_at = 12;
  // Timestamp of last modification.
  google.protobuf.Timestamp modified_at = 13;
  // Timestamp when the instance was started.
  google.protobuf.Timestamp started_at = 14;
  // Timestamp when the instance was stopped.
  google.protobuf.Timestamp stopped_at = 15;
}

// Configuration override for a specific pipeline step.
message StepConfigOverride {
  // Whether this step is enabled.
  bool enabled = 1;
  // Custom configuration for this step.
  ai.pipestream.data.v1.ProcessConfiguration custom_config = 2;
  // Maximum retry attempts for this step.
  int32 max_retries = 3;
  // Timeout duration for this step.
  google.protobuf.Duration step_timeout = 4;
  // Priority of this step.
  int32 priority = 5;
}

// Runtime status of a pipeline instance.
enum PipelineInstanceStatus {
  // Unspecified status.
  PIPELINE_INSTANCE_STATUS_UNSPECIFIED = 0;
  // Instance is stopped.
  PIPELINE_INSTANCE_STATUS_STOPPED = 1;
  // Instance is starting up.
  PIPELINE_INSTANCE_STATUS_STARTING = 2;
  // Instance is running.
  PIPELINE_INSTANCE_STATUS_RUNNING = 3;
  // Instance is stopping.
  PIPELINE_INSTANCE_STATUS_STOPPING = 4;
  // Instance encountered an error.
  PIPELINE_INSTANCE_STATUS_ERROR = 5;
  // Instance is suspended.
  PIPELINE_INSTANCE_STATUS_SUSPENDED = 6;
}

// Module registration information for service discovery.
//
// Tracks registered modules with network location and health check status.
// Health status is obtained via the standard grpc.health.v1.Health service.
message ModuleRegistration {
  // Unique module identifier.
  string module_id = 1;
  // Hostname or IP address where the module is running.
  string host = 2;
  // Port number for the module's gRPC service.
  int32 port = 3;
  // Timestamp when the module was registered.
  google.protobuf.Timestamp registered_at = 4;
  // Timestamp of the last successful health check.
  google.protobuf.Timestamp last_health_check = 5;
  // Additional module metadata.
  map<string, string> metadata = 6;
}

// Visibility scope for module definitions.
enum ModuleVisibility {
  // Unspecified visibility.
  MODULE_VISIBILITY_UNSPECIFIED = 0;
  // Module is publicly available to all clusters.
  MODULE_VISIBILITY_PUBLIC = 1;
  // Module is private to a specific cluster.
  MODULE_VISIBILITY_PRIVATE = 2;
  // Module is restricted to specific clusters.
  MODULE_VISIBILITY_RESTRICTED = 3;
}

// Response from DNS-like node resolution.
//
// Returns node details, outgoing edges, and module definition without requiring the full graph.
// Includes cache hit status for performance monitoring.
message NodeLookupResponse {
  // Resolved graph node.
  GraphNode node = 1;
  // Outgoing edges from this node.
  repeated GraphEdge outgoing_edges = 2;
  // Module definition for this node.
  ModuleDefinition module = 3;
  // Whether this response was served from cache.
  bool cache_hit = 4;
}

// Cross-cluster node lookup request.
//
// Enables discovery of nodes across cluster boundaries for cross-cluster routing.
message CrossClusterNodeLookup {
  // Source cluster initiating the lookup.
  string source_cluster_id = 1;
  // Target cluster containing the desired node.
  string target_cluster_id = 2;
  // Node ID to look up in the target cluster.
  string node_id = 3;
  // Optional routing hint for faster resolution.
  string routing_hint = 4;
}

// Complete network topology for visualization.
//
// Cluster-aware topology snapshot including nodes, edges, and cross-cluster connections.
// Can optionally include nodes from subscribed clusters.
message NetworkTopology {
  // Primary cluster ID for this topology.
  string cluster_id = 1;
  // All nodes in this topology.
  repeated GraphNode nodes = 2;
  // All edges within the primary cluster.
  repeated GraphEdge edges = 3;
  // Cross-cluster edges connecting to other clusters.
  repeated CrossClusterEdge cross_cluster_edges = 4;
  // Cluster subscription relationships.
  repeated ClusterSubscription subscriptions = 5;
  // Timestamp when this snapshot was taken.
  google.protobuf.Timestamp snapshot_time = 6;
  // Whether this topology includes nodes from subscribed clusters.
  bool includes_subscribed_clusters = 7;
}

// Edge connecting nodes across cluster boundaries.
//
// Includes loop prevention via max_hops to prevent infinite routing cycles.
message CrossClusterEdge {
  // Unique identifier for this cross-cluster edge.
  string edge_id = 1;
  // Source cluster ID.
  string from_cluster_id = 2;
  // Source node ID.
  string from_node_id = 3;
  // Target cluster ID.
  string to_cluster_id = 4;
  // Target node ID.
  string to_node_id = 5;
  // Transport mechanism for cross-cluster communication.
  TransportType transport_type = 6;
  // Kafka topic for cross-cluster messaging routing.
  string bridge_topic = 7;
  // Maximum hop count to prevent infinite loops.
  int32 max_hops = 8;
}

// Cluster subscription defining node visibility relationships.
//
// Enables one cluster to discover and use nodes from another cluster.
message ClusterSubscription {
  // Cluster that is subscribing to another cluster's nodes.
  string subscriber_cluster_id = 1;
  // Cluster providing nodes to the subscriber.
  string provider_cluster_id = 2;
  // Optional filter limiting subscription to specific node types.
  repeated string allowed_node_types = 3;
  // Whether the provider can also see the subscriber's nodes.
  bool bidirectional = 4;
  // Timestamp when the subscription was created.
  google.protobuf.Timestamp subscribed_at = 5;
}
